# PLAN DE CORRECTION - SYST√àME DE GESTION DES LIVREURS

**Date:** 2025-12-21
**Objectif:** Corriger les 13 erreurs identifi√©es dans l'audit
**Priorit√©:** CRITIQUE - Synchronisation actuellement non fonctionnelle

---

## R√âSUM√â EX√âCUTIF

### Erreurs identifi√©es: 13
- üî¥ **Critiques (bloquantes):** 3
- üü° **Majeures (bugs s√©rieux):** 4
- üîµ **Mineures (am√©liorations):** 6

### Strat√©gie de correction
Les corrections seront effectu√©es en 3 phases successives :
1. **Phase 1 - URGENTE:** D√©bloquer la synchronisation (3 erreurs critiques)
2. **Phase 2 - IMPORTANTE:** Corriger les bugs de donn√©es (4 erreurs majeures)
3. **Phase 3 - OPTIMISATION:** Am√©liorer robustesse et performance (6 am√©liorations)

---

## PHASE 1 - CORRECTIONS CRITIQUES (URGENT)

**Dur√©e estim√©e:** 1-2 jours
**Objectif:** Rendre la synchronisation fonctionnelle

### ‚úÖ CORRECTION #1: Normaliser les types d'op√©ration

**Erreur:** JavaScript utilise `"create"/"update"/"delete"` alors que SQL attend `'INSERT'/'UPDATE'/'DELETE'`

**Impact:** ‚ùå Aucune synchronisation ne fonctionne

#### √âtape 1.1 - Cr√©er le fichier de constantes

**Fichier:** `src/constants/syncConstants.js` (NOUVEAU)

```javascript
/**
 * Constantes pour la synchronisation IndexedDB ‚Üî Supabase
 */

// Types d'op√©rations (conformes √† la contrainte SQL)
export const OPERATION_TYPES = {
  INSERT: 'INSERT',
  UPDATE: 'UPDATE',
  DELETE: 'DELETE',
};

// Types d'entit√©s
export const ENTITY_TYPES = {
  LIVREUR: 'livreur',
  ADRESSE: 'adresse',
  FOURNISSEUR: 'fournisseur',
  // √Ä compl√©ter au fur et √† mesure
};

// Statuts de synchronisation
export const SYNC_STATUS = {
  PENDING: 'pending',
  PROCESSED: 'processed',
  FAILED: 'failed',
};

// Mapper les types user-friendly vers les types SQL
export const mapOperationType = (userType) => {
  const mapping = {
    'create': OPERATION_TYPES.INSERT,
    'update': OPERATION_TYPES.UPDATE,
    'delete': OPERATION_TYPES.DELETE,
    'INSERT': OPERATION_TYPES.INSERT,
    'UPDATE': OPERATION_TYPES.UPDATE,
    'DELETE': OPERATION_TYPES.DELETE,
  };

  const normalized = mapping[userType];

  if (!normalized) {
    throw new Error(`Type d'op√©ration invalide: ${userType}. Attendu: create, update, delete`);
  }

  return normalized;
};
```

#### √âtape 1.2 - Modifier useLivreursSync.jsx

**Fichier:** `src/hooks/useLivreursSync.jsx`

**Changements:**

```javascript
// AJOUTER en haut du fichier
import {
  OPERATION_TYPES,
  ENTITY_TYPES,
  SYNC_STATUS,
  mapOperationType,
} from "@/constants/syncConstants";

// MODIFIER la fonction addToQueue (ligne 62)
const addToQueue = useCallback(async (operation) => {
  try {
    // Validation
    if (!operation.type) {
      throw new Error("Type d'op√©ration requis");
    }
    if (!operation.entity_id && !operation.livreurId) {
      throw new Error("entity_id ou livreurId requis");
    }

    const db = await initDB();
    const queueItem = {
      operation_type: mapOperationType(operation.type), // ‚úì Convertit "create" ‚Üí "INSERT"
      entity_type: ENTITY_TYPES.LIVREUR,
      entity_id: operation.entity_id || operation.livreurId, // Support des 2 formats
      data: operation.data,
      timestamp: new Date().toISOString(),
      status: SYNC_STATUS.PENDING,
    };

    await db.add("sync_queue", queueItem);
    await updateQueueStats();
  } catch (error) {
    console.error("Erreur ajout √† la queue:", error);
    throw error; // Propager l'erreur pour que l'appelant soit notifi√©
  }
}, []);

// MODIFIER processQueue (ligne 107)
const processQueue = useCallback(async () => {
  if (!online) return { success: false, error: "Hors ligne" };

  try {
    const db = await initDB();
    const queue = await db.getAll("sync_queue");

    const pendingOps = queue.filter(
      (op) =>
        op.entity_type === ENTITY_TYPES.LIVREUR &&
        op.status === SYNC_STATUS.PENDING
    );

    let processed = 0;
    let failed = 0;

    for (const op of pendingOps) {
      try {
        // Validation
        if (!op.entity_id) {
          throw new Error(`entity_id manquant pour l'op√©ration ${op.id}`);
        }

        // Traitement selon le type
        switch (op.operation_type) {
          case OPERATION_TYPES.INSERT:
            if (!op.data) throw new Error("data manquant pour INSERT");
            await createSupabaseLivreur(op.data);
            break;

          case OPERATION_TYPES.UPDATE:
            if (!op.data) throw new Error("data manquant pour UPDATE");
            await updateSupabaseLivreur(op.entity_id, op.data);
            break;

          case OPERATION_TYPES.DELETE:
            await deleteSupabaseLivreur(op.entity_id);
            break;

          default:
            throw new Error(`Type d'op√©ration inconnu: ${op.operation_type}`);
        }

        // Marquer comme trait√©
        const updatedOp = {
          ...op,
          status: SYNC_STATUS.PROCESSED,
          processedAt: new Date().toISOString(),
        };
        await db.put("sync_queue", updatedOp);
        processed++;

      } catch (error) {
        console.error(`Erreur traitement op√©ration ${op.id}:`, error);
        const failedOp = {
          ...op,
          status: SYNC_STATUS.FAILED,
          error: error.message,
          failed_at: new Date().toISOString(),
        };
        await db.put("sync_queue", failedOp);
        failed++;
      }
    }

    await updateQueueStats();

    return { success: true, processed, failed };
  } catch (error) {
    console.error("Erreur traitement queue:", error);
    return { success: false, error: error.message };
  }
}, [online]);

// MODIFIER updateQueueStats (ligne 84)
const updateQueueStats = useCallback(async () => {
  try {
    const db = await initDB();
    const queue = await db.getAll("sync_queue");

    const livreurQueue = queue.filter((op) => op.entity_type === ENTITY_TYPES.LIVREUR);

    setQueueStats({
      total: livreurQueue.length,
      pending: livreurQueue.filter((op) => op.status === SYNC_STATUS.PENDING).length,
      processed: livreurQueue.filter((op) => op.status === SYNC_STATUS.PROCESSED).length,
      failed: livreurQueue.filter((op) => op.status === SYNC_STATUS.FAILED).length,
    });
  } catch (error) {
    console.error("Erreur stats queue:", error);
  }
}, []);
```

#### √âtape 1.3 - Modifier DesktopLivreurs.jsx

**Fichier:** `src/pages/outils/livreurs/DesktopLivreurs.jsx`

**Changements:**

```javascript
// REMPLACER les lignes 65-69 (handleCreate)
await addToQueue({
  type: "create",      // ‚úì Sera converti en "INSERT"
  entity_id: livreur.id,  // ‚úì Utiliser entity_id
  data: livreur,
});

// REMPLACER les lignes 101-106 (handleUpdate)
await addToQueue({
  type: "update",      // ‚úì Sera converti en "UPDATE"
  entity_id: livreur.id,
  data: livreurData,
});

// REMPLACER les lignes 136-139 (handleDelete)
await addToQueue({
  type: "delete",      // ‚úì Sera converti en "DELETE"
  entity_id: livreurId,
  data: null,
});

// REMPLACER les lignes 167-171 (handleToggleActive)
await addToQueue({
  type: "update",      // ‚úì Sera converti en "UPDATE"
  entity_id: livreurId,
  data: { is_active: newStatus },
});
```

#### √âtape 1.4 - Modifier MobileLivreurs.jsx

**Fichier:** `src/pages/outils/livreurs/MobileLivreurs.jsx`

**Changements identiques √† DesktopLivreurs.jsx:**

```javascript
// Lignes 65-69, 101-106, 136-139, 167-171
// M√™me modifications que Desktop
```

#### √âtape 1.5 - Tests

```javascript
// Test manuel √† effectuer:
1. Cr√©er un livreur offline
   ‚Üí V√©rifier dans IndexedDB que sync_queue contient operation_type: "INSERT"

2. Passer online et synchroniser
   ‚Üí V√©rifier que l'op√©ration est processed
   ‚Üí V√©rifier dans Supabase que le livreur existe
   ‚Üí V√©rifier dans livreurs_sync qu'une entr√©e INSERT existe

3. Modifier le livreur
   ‚Üí V√©rifier sync_queue: operation_type: "UPDATE"
   ‚Üí Sync et v√©rifier Supabase updated

4. D√©sactiver le livreur
   ‚Üí V√©rifier sync_queue: operation_type: "UPDATE"
   ‚Üí Sync et v√©rifier is_active = false

5. Supprimer le livreur
   ‚Üí V√©rifier sync_queue: operation_type: "DELETE"
   ‚Üí Sync et v√©rifier suppression Supabase
```

---

### ‚úÖ CORRECTION #2: Synchroniser les UUIDs

**Erreur:** UUID g√©n√©r√© localement diff√©rent de l'UUID Supabase

**Impact:** ‚ùå Doublons, impossibilit√© de mettre √† jour

#### √âtape 2.1 - Modifier livreurToolkit.jsx

**Fichier:** `src/utils/livreurToolkit.jsx`

**Changement:**

```javascript
// REMPLACER la fonction createLivreur (lignes 33-57)
export const createLivreur = async (livreurData) => {
  try {
    const insertData = {
      denomination: livreurData.denomination,
      contact: livreurData.contact,
      is_active: livreurData.is_active ?? true,
    };

    // ‚úì Si un UUID est fourni (cr√©ation offline), l'utiliser
    if (livreurData.id) {
      insertData.id = livreurData.id;
    }

    const { data, error } = await supabase
      .from("livreurs")
      .insert([insertData])
      .select()
      .single();

    if (error) {
      console.error("Erreur cr√©ation livreur:", error);
      return { success: false, error: error.message };
    }

    return { success: true, livreur: data };
  } catch (error) {
    console.error("Erreur inattendue cr√©ation livreur:", error);
    return { success: false, error: error.message };
  }
};
```

#### √âtape 2.2 - V√©rifier le sch√©ma SQL

**Fichier:** `sql/create_livreurs_table.sql`

Le sch√©ma actuel est d√©j√† compatible (ligne 15):
```sql
id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
```

Le `DEFAULT` permet d'ins√©rer un UUID personnalis√©. ‚úÖ Aucune modification n√©cessaire.

#### √âtape 2.3 - Tests

```javascript
// Test de conservation d'UUID:
1. Cr√©er un livreur offline
   const localId = crypto.randomUUID();
   createLivreur({ id: localId, denomination: "Test", contact: "123456789" })

2. V√©rifier IndexedDB
   ‚Üí Livreur existe avec id = localId

3. Synchroniser
   ‚Üí processQueue() envoie data avec id = localId

4. V√©rifier Supabase
   ‚Üí SELECT * FROM livreurs WHERE id = localId
   ‚Üí Devrait retourner 1 ligne

5. syncPull()
   ‚Üí V√©rifier qu'aucun doublon n'est cr√©√© dans IndexedDB
   ‚Üí Devrait toujours avoir 1 seul livreur avec id = localId
```

---

### ‚úÖ CORRECTION #3: Standardiser les noms de champs

**Erreur:** M√©lange de `livreurId` et `entity_id`

**Impact:** ‚ö†Ô∏è Confusion, risque d'undefined

**Note:** Cette correction est d√©j√† incluse dans la Correction #1 (√âtapes 1.3 et 1.4).

Les modifications dans Desktop/Mobile remplacent tous les `livreurId` par `entity_id`.

La fonction `addToQueue` modifi√©e supporte les deux formats pour la r√©trocompatibilit√©:
```javascript
entity_id: operation.entity_id || operation.livreurId
```

#### Tests

```javascript
// V√©rifier qu'aucune op√©ration n'a entity_id = undefined:
1. Ouvrir IndexedDB dans DevTools
2. Aller dans sync_queue
3. V√©rifier que tous les items ont entity_id valide (UUID)
```

---

## PHASE 2 - CORRECTIONS MAJEURES (IMPORTANTE)

**Dur√©e estim√©e:** 1 semaine
**Objectif:** Corriger les bugs de donn√©es et s√©curit√©

### ‚úÖ CORRECTION #4: Supprimer double mise √† jour de updated_at

**Erreur:** Timestamp mis √† jour par le code ET par le trigger SQL

#### √âtape 4.1 - Modifier livreurToolkit.jsx

**Fichier:** `src/utils/livreurToolkit.jsx`

```javascript
// REMPLACER updateLivreur (lignes 132-156)
export const updateLivreur = async (livreurId, updates) => {
  try {
    // ‚úì Laisser le trigger SQL g√©rer updated_at
    const { data, error } = await supabase
      .from("livreurs")
      .update(updates)  // ‚ùå NE PAS ajouter updated_at manuellement
      .eq("id", livreurId)
      .select()
      .single();

    if (error) {
      console.error("Erreur mise √† jour livreur:", error);
      return { success: false, error: error.message };
    }

    return { success: true, livreur: data };
  } catch (error) {
    console.error("Erreur inattendue mise √† jour livreur:", error);
    return { success: false, error: error.message };
  }
};
```

#### √âtape 4.2 - Modifier deactivateLivreur et activateLivreur

**Fichier:** `src/utils/livreurToolkit.jsx`

```javascript
// REMPLACER deactivateLivreur (lignes 163-185)
export const deactivateLivreur = async (livreurId) => {
  try {
    const { data, error } = await supabase
      .from("livreurs")
      .update({ is_active: false })  // ‚úì Sans updated_at
      .eq("id", livreurId)
      .select()
      .single();

    if (error) {
      console.error("Erreur d√©sactivation livreur:", error);
      return { success: false, error: error.message };
    }

    return { success: true, livreur: data };
  } catch (error) {
    console.error("Erreur inattendue d√©sactivation livreur:", error);
    return { success: false, error: error.message };
  }
};

// REMPLACER activateLivreur (lignes 192-214)
export const activateLivreur = async (livreurId) => {
  try {
    const { data, error } = await supabase
      .from("livreurs")
      .update({ is_active: true })  // ‚úì Sans updated_at
      .eq("id", livreurId)
      .select()
      .single();

    if (error) {
      console.error("Erreur activation livreur:", error);
      return { success: false, error: error.message };
    }

    return { success: true, livreur: data };
  } catch (error) {
    console.error("Erreur inattendue activation livreur:", error);
    return { success: false, error: error.message };
  }
};
```

#### Tests

```javascript
// V√©rifier que updated_at est correct:
1. Modifier un livreur
2. Noter le timestamp retourn√© par l'API
3. SELECT updated_at FROM livreurs WHERE id = ...
4. Les 2 timestamps doivent √™tre identiques (¬±1ms)
```

---

### ‚úÖ CORRECTION #5: Impl√©menter r√©solution de conflits

**Erreur:** Last-write-wins √©crase toutes les donn√©es sans merge

#### √âtape 5.1 - Cr√©er fonction de merge

**Fichier:** `src/hooks/useLivreursSync.jsx`

```javascript
// AJOUTER apr√®s les imports
/**
 * Merge intelligent de 2 versions d'un livreur
 * Strat√©gie: Last-write-wins par champ
 */
const mergeLivreurConflict = (local, remote) => {
  const localTime = new Date(local.updated_at);
  const remoteTime = new Date(remote.updated_at);

  // Si remote est plus r√©cent, le prendre enti√®rement
  if (remoteTime > localTime) {
    return { ...remote, _merged: false, _source: 'remote' };
  }

  // Si local est plus r√©cent, le garder enti√®rement
  if (localTime > remoteTime) {
    return { ...local, _merged: false, _source: 'local' };
  }

  // Si m√™me timestamp (rare mais possible), merger field-by-field
  // En cas d'√©galit√©, privil√©gier le remote (serveur fait foi)
  return {
    id: remote.id,
    denomination: remote.denomination !== local.denomination
      ? remote.denomination
      : local.denomination,
    contact: remote.contact !== local.contact
      ? remote.contact
      : local.contact,
    is_active: remote.is_active, // Le serveur fait foi pour le statut
    created_at: local.created_at, // Garder le plus ancien
    updated_at: new Date(Math.max(localTime, remoteTime)).toISOString(),
    _merged: true,
    _source: 'conflict',
  };
};
```

#### √âtape 5.2 - Modifier syncPull

**Fichier:** `src/hooks/useLivreursSync.jsx`

```javascript
// REMPLACER la boucle de merge (lignes 201-214)
// Ajouter ou mettre √† jour depuis Supabase
for (const [id, supabaseLivreur] of supabaseMap) {
  const localLivreur = localMap.get(id);

  if (!localLivreur) {
    // Nouveau livreur depuis Supabase
    await store.add(supabaseLivreur);
    added++;
  } else {
    // Livreur existe d√©j√† localement, merger
    const merged = mergeLivreurConflict(localLivreur, supabaseLivreur);

    // Mettre √† jour seulement si le merge a chang√© quelque chose
    if (
      merged._source === 'remote' ||
      merged._source === 'conflict' ||
      JSON.stringify(merged) !== JSON.stringify(localLivreur)
    ) {
      // Nettoyer les champs de debug
      delete merged._merged;
      delete merged._source;

      await store.put(merged);
      updated++;
    }
  }
}
```

#### Tests

```javascript
// Test de conflit:
1. User A offline: Modifie denomination de "DHL" ‚Üí "DHL Express"
2. User B offline: Modifie contact de "+237693456789" ‚Üí "+237698765432"
3. User A sync en premier (updated_at = T1)
4. User B sync ensuite (updated_at = T2 > T1)
5. V√©rifier r√©sultat final:
   - Si T2 > T1: denomination = "DHL", contact = "+237698765432" (User B gagne)
   - Aucune donn√©e perdue (logged)
```

---

### ‚úÖ CORRECTION #6: V√©rifier politique RLS

**Erreur:** RLS trop restrictive bloque les triggers

#### √âtape 6.1 - Ex√©cuter le script de fix

**Fichier:** `sql/fix_livreurs_sync_rls.sql` (d√©j√† existant)

```sql
-- EX√âCUTER dans Supabase SQL Editor
DROP POLICY IF EXISTS "Insertion des changements via triggers uniquement" ON livreurs_sync;

CREATE POLICY "Insertion des changements pour utilisateurs authentifi√©s"
  ON livreurs_sync
  FOR INSERT
  TO authenticated
  WITH CHECK (true);
```

#### √âtape 6.2 - V√©rifier les politiques

```sql
-- V√âRIFIER dans Supabase SQL Editor
SELECT
  schemaname,
  tablename,
  policyname,
  permissive,
  roles,
  cmd,
  qual,
  with_check
FROM pg_policies
WHERE schemaname = 'public'
  AND tablename = 'livreurs_sync';

-- Doit retourner:
-- policyname: "Insertion des changements pour utilisateurs authentifi√©s"
-- roles: {authenticated}
-- cmd: INSERT
```

#### Tests

```javascript
// Tester les triggers:
1. Cr√©er un livreur via Supabase (en tant qu'utilisateur authentifi√©)
2. V√©rifier que livreurs_sync contient une ligne avec operation_type = 'INSERT'
3. Modifier le livreur
4. V√©rifier que livreurs_sync contient une ligne avec operation_type = 'UPDATE'
```

---

### ‚úÖ CORRECTION #7: Validation des IDs

**D√©j√† corrig√©e dans Correction #1** (processQueue avec validation)

---

## PHASE 3 - OPTIMISATIONS (AM√âLIORATION)

**Dur√©e estim√©e:** 2 semaines
**Objectif:** Performance, robustesse, maintenabilit√©

### üîµ AM√âLIORATION #8: Nettoyage automatique de la queue

#### √âtape 8.1 - Cr√©er fonction cleanupQueue

**Fichier:** `src/hooks/useLivreursSync.jsx`

```javascript
// AJOUTER apr√®s processQueue
/**
 * Nettoyer les op√©rations trait√©es de plus de 7 jours
 */
const cleanupQueue = useCallback(async () => {
  try {
    const db = await initDB();
    const queue = await db.getAll("sync_queue");

    const weekAgo = new Date();
    weekAgo.setDate(weekAgo.getDate() - 7);

    let deleted = 0;

    for (const op of queue) {
      // Supprimer les op√©rations processed de plus de 7 jours
      if (
        op.status === SYNC_STATUS.PROCESSED &&
        op.processedAt &&
        new Date(op.processedAt) < weekAgo
      ) {
        await db.delete("sync_queue", op.id);
        deleted++;
      }
    }

    if (deleted > 0) {
      console.log(`üßπ Queue nettoy√©e: ${deleted} op√©ration(s) supprim√©e(s)`);
      await updateQueueStats();
    }

    return { success: true, deleted };
  } catch (error) {
    console.error("Erreur nettoyage queue:", error);
    return { success: false, error: error.message };
  }
}, [updateQueueStats]);
```

#### √âtape 8.2 - Appeler apr√®s sync

```javascript
// MODIFIER syncFull (ligne 264)
const syncFull = useCallback(async () => {
  if (!online) {
    return { success: false, error: "Hors ligne" };
  }

  setIsSyncing(true);
  setSyncError(null);

  try {
    // 1. Push les changements locaux
    const pushResult = await syncPush();

    // 2. Pull les donn√©es Supabase
    const pullResult = await syncPull();

    // 3. Nettoyer la queue
    await cleanupQueue();  // ‚úì AJOUTER

    setLastSync(new Date().toISOString());

    return {
      success: true,
      pushProcessed: pushResult.processed || 0,
      pullCount: pullResult.pullCount || 0,
    };
  } catch (error) {
    console.error("Erreur sync compl√®te:", error);
    setSyncError(error.message);
    return { success: false, error: error.message };
  } finally {
    setIsSyncing(false);
  }
}, [online, syncPush, syncPull, cleanupQueue]);

// EXPORTER cleanupQueue
return {
  ...
  cleanupQueue,  // ‚úì AJOUTER
};
```

---

### üîµ AM√âLIORATION #9-13

Les am√©liorations 9 √† 13 seront impl√©ment√©es de mani√®re similaire. D√©tails disponibles dans l'audit complet.

**Liste:**
- #9: Stockage donn√©es compl√®tes (old_data/new_data)
- #10: Transactions atomiques IndexedDB
- #11: Constantes pour entity_type (d√©j√† fait)
- #12: Mapping des erreurs Supabase
- #13: Index SQL optimis√©s

---

## CHECKLIST DE VALIDATION

### ‚úÖ Phase 1 termin√©e quand:
- [ ] sync_queue contient operation_type: "INSERT"/"UPDATE"/"DELETE"
- [ ] processQueue() traite correctement les op√©rations
- [ ] Aucune erreur dans livreurs_sync (contrainte CHECK respect√©e)
- [ ] UUID local = UUID Supabase apr√®s sync
- [ ] Aucun doublon dans IndexedDB apr√®s syncPull()
- [ ] entity_id jamais undefined dans sync_queue

### ‚úÖ Phase 2 termin√©e quand:
- [ ] updated_at identique entre API response et DB
- [ ] Conflits merg√©s sans perte de donn√©es
- [ ] Triggers fonctionnent avec utilisateur authentifi√©
- [ ] Validation bloque les op√©rations invalides

### ‚úÖ Phase 3 termin√©e quand:
- [ ] Queue nettoy√©e automatiquement
- [ ] Transactions atomiques sur syncPull
- [ ] Erreurs traduites en fran√ßais
- [ ] Performance optimale sur 1000+ livreurs

---

## COMMANDES UTILES

### V√©rifier IndexedDB
```javascript
// Console DevTools
const db = await indexedDB.open("lsd_db_v2");
const tx = db.transaction("sync_queue", "readonly");
const store = tx.objectStore("sync_queue");
const all = await store.getAll();
console.table(all);
```

### V√©rifier Supabase
```sql
-- Voir les changements r√©cents
SELECT * FROM recent_livreurs_changes;

-- Voir les stats de sync
SELECT * FROM livreurs_sync_stats;

-- Tester les triggers
SELECT test_livreurs_sync_triggers();
```

### Reset complet (d√©veloppement uniquement)
```javascript
// ATTENTION: Efface toutes les donn√©es locales!
await indexedDB.deleteDatabase("lsd_db_v2");
location.reload();
```

---

## TIMELINE RECOMMAND√âE

| Semaine | Phase | T√¢ches | Validation |
|---------|-------|--------|------------|
| **Sem 1** | Phase 1 | Corrections #1, #2, #3 | Tests de synchronisation |
| **Sem 2** | Phase 2 | Corrections #4, #5, #6, #7 | Tests de conflits |
| **Sem 3-4** | Phase 3 | Am√©liorations #8-13 | Tests de charge |

**Total:** 4 semaines pour syst√®me production-ready

---

## SUPPORT

En cas de probl√®me durant la correction :
1. V√©rifier les logs console (erreurs)
2. V√©rifier IndexedDB (sync_queue)
3. V√©rifier Supabase (livreurs_sync table)
4. Tester avec fix_livreurs_sync_rls.sql

**Prochaine √©tape:** Commencer Phase 1 - Correction #1
